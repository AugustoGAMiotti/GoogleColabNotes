{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3GhsmyV8yPo29YHLpeuB4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AugustoGAMiotti/GoogleColabNotes/blob/main/Web%20Scraping/Regex_and_BeautfulSoup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://colab.research.google.com/github/rpi-techfundamentals/introml_website_fall_2020/blob/master/site/notebooks/03-viz-api-scraper/04-strings-regular-expressions.ipynb\n",
        "https://colab.research.google.com/github/jirvingphd/my_data_science_notes/blob/master/Web_Scraping_101_share.ipynb#scrollTo=7JpBMzWysPb0\n",
        "https://towardsdatascience.com/web-scraping-regular-expressions-and-data-visualization-doing-it-all-in-python-37a1aade7924\n",
        "https://medium.com/geekculture/web-scraping-tables-in-python-using-beautiful-soup-8bbc31c5803e"
      ],
      "metadata": {
        "id": "h3gwIO7TiCpd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7ga3GJEhqwz",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install bs_ds\n",
        "!pip install fake_useragent\n",
        "!pip install lxml"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chamada da URL - Metodo 1"
      ],
      "metadata": {
        "id": "AFuxlOPe5EVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "#url = 'https://www.xerblade.com/p/fateextra-walkthrough-enemy-patterns.html?m=0#week1'\n",
        "url = 'https://gamepress.gg/grandorder/servants'\n",
        "\n",
        "response = requests.get(url, timeout=3)\n",
        "print('Status code: ',response.status_code)\n",
        "if response.status_code==200:\n",
        "    print('Connection successfull.\\n\\n')\n",
        "else:\n",
        "    print('Error. Check status code table.\\n\\n')\n",
        "\n",
        "print(f\"{'---'*20}\\n\\tContents of Response.items():\\n{'---'*20}\")\n",
        "\n",
        "for k,v in response.headers.items():\n",
        "    print(f\"{k:{25}}: {v:{40}}\") # Note: add :{number} inside of a"
      ],
      "metadata": {
        "id": "teUkn2ZZh5vM",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chamada da URL - Metodo 2"
      ],
      "metadata": {
        "id": "dIRhbcoh5BOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "url = 'https://gamepress.gg/grandorder/servants'\n",
        "response = requests.get(url, timeout=3)\n",
        "r = requests.get('https://gamepress.gg/grandorder/servants')\n",
        "#Coletando o conte√∫do\n",
        "c = r.content\n",
        "from bs4 import BeautifulSoup\n",
        "#Criando Soup\n",
        "soup = BeautifulSoup(c)\n",
        "soup"
      ],
      "metadata": {
        "id": "nOPS2f_ViQx3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "servants = soup.find_all('tr', class_ = 'servants-new-row')\n",
        "for servant in servants:\n",
        "    servant_name = servant.select_one('span[class=\"servant-list-title\"]').get_text(strip=True)\n",
        "    servant_class = servant.select_one('span[class=\"servant-list-class\"]').get_text(strip=True)\n",
        "    print(f'{servant_name} class {servant_class}')"
      ],
      "metadata": {
        "id": "CnzQ33b2ueR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pega todas as classes\n",
        "\n",
        "import pandas as pd\n",
        "servants_data = []\n",
        "\n",
        "servants = soup.find_all('tr', class_ = 'servants-new-row')\n",
        "for servant in servants:\n",
        "    servant_no = servant.find('td', class_ = 'servant-no').get_text(strip=True)\n",
        "    servant_name = servant.select_one('span[class=\"servant-list-title\"]').get_text(strip=True)\n",
        "    servant_class = servant.select_one('span[class=\"servant-list-class\"]').get_text(strip=True)\n",
        "    servants_data.append([servant_no, servant_name, servant_class])\n",
        "\n",
        "df = pd.DataFrame(servants_data, columns=['ID', 'Name', 'Class'])\n",
        "\n",
        "df.to_csv('servants.csv')\n",
        "df\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "KWBoCWXLw-Oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pega uma ou algumas classes:\n",
        "\n",
        "import pandas as pd\n",
        "servant_data = []\n",
        "\n",
        "servants = soup.find_all('tr', class_ = 'servants-new-row')\n",
        "for servant in servants:\n",
        "    servant_class = servant.select_one('span[class=\"servant-list-class\"]').get_text(strip=True)\n",
        "    #servant_class == 'Shielder' or servant_class == 'Ruler' or servant_class == 'Avenger' or servant_class == 'Moon Cancer':\n",
        "    #servant_class == 'Alter Ego' or servant_class == 'Foreigner' or servant_class == 'Pretender' or servant_class == 'Beast':\n",
        "    if servant_class == 'Berserker':\n",
        "        servant_no = servant.find('td', class_ = 'servant-no').get_text(strip=True)\n",
        "        servant_name = servant.select_one('span[class=\"servant-list-title\"]').get_text(strip=True)\n",
        "        server_rarity = servant.find('td', class_ = 'servant-rarity').get_text(strip=True)\n",
        "        servant_data.append([servant_no, servant_name, servant_class, server_rarity])\n",
        "\n",
        "df_servant = pd.DataFrame(servant_data, columns=['ID', 'Name', 'Class', 'Rarity'])\n",
        "\n",
        "df_servant.to_csv('berserker.csv')\n",
        "df_servant"
      ],
      "metadata": {
        "id": "xXKg19en0zVq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}